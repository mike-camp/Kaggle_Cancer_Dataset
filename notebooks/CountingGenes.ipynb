{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>[FAM58A, STAR, STAR, STAR, STAR, FAM58A, STAR,...</td>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>[CBL, CBL, EGFR, MET, CBL, CBL, MET, EGFR, KRA...</td>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>[CBL, CBL, EGFR, MET, CBL, CBL, MET, EGFR, KRA...</td>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>[JAK2, JAK2, CBL, CBL, CBL, FLT3, CBL, V617F, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>[CBL, CBL, CBL, CBL, CBL, CBL, EGFR, CBL, CBL,...</td>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...   \n",
       "1   Abstract Background  Non-small cell lung canc...   \n",
       "2   Abstract Background  Non-small cell lung canc...   \n",
       "3  Recent evidence has demonstrated that acquired...   \n",
       "4  Oncogenic mutations in the monomeric Casitas B...   \n",
       "\n",
       "                                           processed  ID    Gene  \\\n",
       "0  [FAM58A, STAR, STAR, STAR, STAR, FAM58A, STAR,...   0  FAM58A   \n",
       "1  [CBL, CBL, EGFR, MET, CBL, CBL, MET, EGFR, KRA...   1     CBL   \n",
       "2  [CBL, CBL, EGFR, MET, CBL, CBL, MET, EGFR, KRA...   2     CBL   \n",
       "3  [JAK2, JAK2, CBL, CBL, CBL, FLT3, CBL, V617F, ...   3     CBL   \n",
       "4  [CBL, CBL, CBL, CBL, CBL, CBL, EGFR, CBL, CBL,...   4     CBL   \n",
       "\n",
       "              Variation  Class  \n",
       "0  Truncating Mutations      1  \n",
       "1                 W802*      2  \n",
       "2                 Q249E      2  \n",
       "3                 N454D      3  \n",
       "4                 L399V      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(pd.read_pickle('../data/genes-train.pk'),pd.read_csv('../data/training_variants.csv'),\n",
    "               left_index=True,right_index=True)\n",
    "df_test = pd.merge(pd.read_pickle('../data/genes-test.pk'),pd.read_csv('../data/test_variants.csv'),\n",
    "                  left_index=True,right_index=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_series = pd.concat((df_train.processed,df_test.processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "def return_same(x):\n",
    "    return x\n",
    "count_vectorizer = CountVectorizer(analyzer=return_same)\n",
    "vecs = count_vectorizer.fit_transform(text_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.478 +/- 0.028\n",
      "svm: -1.347 +/- 0.014\n",
      "xgb: -1.301 +/- 0.019\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer=return_same)\n",
    "vecs = count_vectorizer.fit_transform(text_series)\n",
    "vecs_train = vecs[:df_train.shape[0]]\n",
    "vecs_test = vecs[df_train.shape[0]:]\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X,y = shuffle(vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=500,learning_rate=.01,n_jobs=-1,subsample=.5)\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.422 +/- 0.054\n",
      "svm: -1.363 +/- 0.013\n",
      "xgb: -1.199 +/- 0.030\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer=return_same,min_df=10)\n",
    "vecs = count_vectorizer.fit_transform(text_series)\n",
    "vecs_train = vecs[:df_train.shape[0]]\n",
    "vecs_test = vecs[df_train.shape[0]:]\n",
    "\n",
    "X,y = shuffle(vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.429 +/- 0.073\n",
      "svm: -1.376 +/- 0.016\n",
      "xgb: -1.216 +/- 0.011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer(analyzer=return_same,min_df=10)\n",
    "vecs = count_vectorizer.fit_transform(text_series)\n",
    "vecs_train = vecs[:df_train.shape[0]]\n",
    "vecs_test = vecs[df_train.shape[0]:]\n",
    "\n",
    "X,y = shuffle(vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.896 +/- 0.001\n",
      "svm: -1.449 +/- 0.023\n",
      "xgb: -1.243 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer=return_same,min_df=10)\n",
    "vecs = tfidf_vectorizer.fit_transform(text_series)\n",
    "vecs_train = vecs[:df_train.shape[0]]\n",
    "vecs_test = vecs[df_train.shape[0]:]\n",
    "\n",
    "X,y = shuffle(vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.897 +/- 0.003\n",
      "svm: -1.601 +/- 0.003\n",
      "xgb: -1.415 +/- 0.051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=50, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,n_jobs=-1)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer=return_same)\n",
    "vecs = tfidf_vectorizer.fit_transform(text_series)\n",
    "gene_vecs = lda.fit_transform(vecs)\n",
    "gene_vecs_train = gene_vecs[:df_train.shape[0]]\n",
    "\n",
    "X,y = shuffle(gene_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.887 +/- 0.004\n",
      "svm: -1.621 +/- 0.026\n",
      "xgb: -1.457 +/- 0.046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=20, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,n_jobs=-1)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer=return_same)\n",
    "vecs = tfidf_vectorizer.fit_transform(text_series)\n",
    "gene_vecs = lda.fit_transform(vecs)\n",
    "gene_vecs_train = gene_vecs[:df_train.shape[0]]\n",
    "\n",
    "X,y = shuffle(gene_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 48026)\n",
      "lr:  -1.917 +/- 0.001\n",
      "svm: -1.925 +/- 0.067\n",
      "xgb: -1.561 +/- 0.057\n"
     ]
    }
   ],
   "source": [
    "df_train_stemmed = pd.merge(pd.read_pickle('../data/stem-train.pk'),pd.read_csv('../data/training_variants.csv'),\n",
    "               left_index=True,right_index=True)\n",
    "df_test_stemmed = pd.merge(pd.read_pickle('../data/stem-test.pk'),pd.read_csv('../data/test_variants.csv'),\n",
    "                  left_index=True,right_index=True)\n",
    "text_series_stem = pd.concat((df_train_stemmed.processed,df_test_stemmed.processed))\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "del df_train['text']\n",
    "del df_test['text']\n",
    "del df_train['processed']\n",
    "del df_test['processed']\n",
    "del df_train_stemmed\n",
    "del df_test_stemmed\n",
    "lda_stem = LatentDirichletAllocation(n_topics=20, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,n_jobs=-1)\n",
    "\n",
    "tfidf_vectorizer_stem = TfidfVectorizer(analyzer=return_same,min_df=15,max_df=.8)\n",
    "stem_vecs = tfidf_vectorizer_stem.fit_transform(text_series_stem)\n",
    "print(stem_vecs.shape)\n",
    "del text_series_stem\n",
    "stem_vecs = lda_stem.fit_transform(stem_vecs)\n",
    "stem_vecs_train = stem_vecs[:df_train.shape[0]]\n",
    "\n",
    "X,y = shuffle(stem_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 48026)\n",
      "lr:  -1.917 +/- 0.001\n",
      "svm: -1.998 +/- 0.040\n",
      "xgb: -1.571 +/- 0.053\n"
     ]
    }
   ],
   "source": [
    "df_train_stemmed = pd.merge(pd.read_pickle('../data/stem-train.pk'),pd.read_csv('../data/training_variants.csv'),\n",
    "               left_index=True,right_index=True)\n",
    "df_test_stemmed = pd.merge(pd.read_pickle('../data/stem-test.pk'),pd.read_csv('../data/test_variants.csv'),\n",
    "                  left_index=True,right_index=True)\n",
    "text_series_stem = pd.concat((df_train_stemmed.processed,df_test_stemmed.processed))\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "del df_train_stemmed\n",
    "del df_test_stemmed\n",
    "lda_stem = LatentDirichletAllocation(n_topics=50, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,n_jobs=-1)\n",
    "\n",
    "tfidf_vectorizer_stem = TfidfVectorizer(analyzer=return_same,min_df=15,max_df=.8)\n",
    "stem_vecs = tfidf_vectorizer_stem.fit_transform(text_series_stem)\n",
    "print(stem_vecs.shape)\n",
    "del text_series_stem\n",
    "stem_vecs = lda_stem.fit_transform(stem_vecs)\n",
    "stem_vecs_train = stem_vecs[:df_train.shape[0]]\n",
    "\n",
    "X,y = shuffle(stem_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_stemmed = pd.merge(pd.read_pickle('../data/stem-train.pk'),pd.read_csv('../data/training_variants.csv'),\n",
    "               left_index=True,right_index=True)\n",
    "df_test_stemmed = pd.merge(pd.read_pickle('../data/stem-test.pk'),pd.read_csv('../data/test_variants.csv'),\n",
    "                  left_index=True,right_index=True)\n",
    "text_series_stem = pd.concat((df_train_stemmed.processed,df_test_stemmed.processed))\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "del df_train_stemmed\n",
    "del df_test_stemmed\n",
    "lda_stem = LatentDirichletAllocation(n_topics=500, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,n_jobs=-1)\n",
    "\n",
    "tfidf_vectorizer_stem = TfidfVectorizer(analyzer=return_same,min_df=15,max_df=.8)\n",
    "stem_vecs = tfidf_vectorizer_stem.fit_transform(text_series_stem)\n",
    "print(stem_vecs.shape)\n",
    "del text_series_stem\n",
    "stem_vecs = lda_stem.fit_transform(stem_vecs)\n",
    "stem_vecs_train = stem_vecs[:df_train.shape[0]]\n",
    "\n",
    "X,y = shuffle(stem_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg_vecs_train = np.hstack((gene_vecs_train, stem_vecs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 70)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_vecs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  -1.847 +/- 0.002\n",
      "svm: -1.622 +/- 0.015\n",
      "xgb: -1.448 +/- 0.040\n"
     ]
    }
   ],
   "source": [
    "X,y = shuffle(sg_vecs_train,df_train.Class)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(C=.01),X,y,scoring='neg_log_loss')\n",
    "svm_scores = cross_val_score(SVC(C=.1,probability=True),X,y,n_jobs=-1,scoring='neg_log_loss')\n",
    "xgb_scores = cross_val_score(XGBClassifier(n_estimators=2000,learning_rate=.05,n_jobs=-1,subsample=.5,\n",
    "                                           objective='multi:softprob',eval_metric='mlogloss')\n",
    "                             ,X,y,scoring='neg_log_loss')\n",
    "print('lr:  {:.3f} +/- {:.3f}'.format(lr_scores.mean(),lr_scores.std()))\n",
    "print('svm: {:.3f} +/- {:.3f}'.format(svm_scores.mean(),svm_scores.std()))\n",
    "print('xgb: {:.3f} +/- {:.3f}'.format(xgb_scores.mean(),xgb_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
